{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "solution.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMxsw8CwMvghsdp3/zj6j8z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Srishtimend/CS4400-Final/blob/main/solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSIt-C2TKXK6",
        "outputId": "b12dd99e-e52f-4b6d-887e-59e3eca8b66c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "%cd /content/gdrive/MyDrive/Colab\\ Notebooks/Final Project\n",
        "!pip install python-Levenshtein scikit-learn pandas numpy\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# from os.path import join\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from os.path import join\n",
        "\n",
        "# 1. read data\n",
        "\n",
        "ltable = pd.read_csv(join('data', \"ltable.csv\"))\n",
        "rtable = pd.read_csv(join('data', \"rtable.csv\"))\n",
        "train = pd.read_csv(join('data', \"train.csv\"))\n",
        "\n",
        "\n",
        "# 2. blocking\n",
        "def pairs2LR(ltable, rtable, candset):\n",
        "    ltable.index = ltable.id\n",
        "    rtable.index = rtable.id\n",
        "    pairs = np.array(candset)\n",
        "    tpls_l = ltable.loc[pairs[:, 0], :]\n",
        "    tpls_r = rtable.loc[pairs[:, 1], :]\n",
        "    tpls_l.columns = [col + \"_l\" for col in tpls_l.columns]\n",
        "    tpls_r.columns = [col + \"_r\" for col in tpls_r.columns]\n",
        "    tpls_l.reset_index(inplace=True, drop=True)\n",
        "    tpls_r.reset_index(inplace=True, drop=True)\n",
        "    LR = pd.concat([tpls_l, tpls_r], axis=1)\n",
        "    return LR\n",
        "\n",
        "\n",
        "def block_by_brand(ltable, rtable):\n",
        "    # ensure brand is str\n",
        "    ltable['brand'] = ltable['brand'].astype(str)\n",
        "    rtable['brand'] = rtable['brand'].astype(str)\n",
        "\n",
        "    # get all brands\n",
        "    brands_l = set(ltable[\"brand\"].values)\n",
        "    brands_r = set(rtable[\"brand\"].values)\n",
        "    brands = brands_l.union(brands_r)\n",
        "\n",
        "    # map each brand to left ids and right ids\n",
        "    brand2ids_l = {b.lower(): [] for b in brands}\n",
        "    brand2ids_r = {b.lower(): [] for b in brands}\n",
        "    for i, x in ltable.iterrows():\n",
        "        brand2ids_l[x[\"brand\"].lower()].append(x[\"id\"])\n",
        "    for i, x in rtable.iterrows():\n",
        "        brand2ids_r[x[\"brand\"].lower()].append(x[\"id\"])\n",
        "\n",
        "    # put id pairs that share the same brand in candidate set\n",
        "    candset = []\n",
        "    for brd in brands:\n",
        "        l_ids = brand2ids_l[brd]\n",
        "        r_ids = brand2ids_r[brd]\n",
        "        for i in range(len(l_ids)):\n",
        "            for j in range(len(r_ids)):\n",
        "                candset.append([l_ids[i], r_ids[j]])\n",
        "    return candset\n",
        "\n",
        "# blocking to reduce the number of pairs to be compared\n",
        "candset = block_by_brand(ltable, rtable)\n",
        "print(\"number of pairs originally\", ltable.shape[0] * rtable.shape[0])\n",
        "print(\"number of pairs after blocking\",len(candset))\n",
        "candset_df = pairs2LR(ltable, rtable, candset)\n",
        "\n",
        "\n",
        "\n",
        "# 3. Feature engineering\n",
        "import Levenshtein as lev\n",
        "\n",
        "def jaccard_similarity(row, attr):\n",
        "    x = set(row[attr + \"_l\"].lower().split())\n",
        "    y = set(row[attr + \"_r\"].lower().split())\n",
        "    return len(x.intersection(y)) / max(len(x), len(y))\n",
        "\n",
        "\n",
        "def levenshtein_distance(row, attr):\n",
        "    x = row[attr + \"_l\"].lower()\n",
        "    y = row[attr + \"_r\"].lower()\n",
        "    return lev.distance(x, y)\n",
        "\n",
        "def feature_engineering(LR):\n",
        "    LR = LR.astype(str)\n",
        "    attrs = [\"title\", \"category\", \"brand\", \"modelno\", \"price\"]\n",
        "    features = []\n",
        "    for attr in attrs:\n",
        "        j_sim = LR.apply(jaccard_similarity, attr=attr, axis=1)\n",
        "        l_dist = LR.apply(levenshtein_distance, attr=attr, axis=1)\n",
        "        features.append(j_sim)\n",
        "        features.append(l_dist)\n",
        "    features = np.array(features).T\n",
        "    return features\n",
        "candset_features = feature_engineering(candset_df)\n",
        "\n",
        "# also perform feature engineering to the training set\n",
        "training_pairs = list(map(tuple, train[[\"ltable_id\", \"rtable_id\"]].values))\n",
        "training_df = pairs2LR(ltable, rtable, training_pairs)\n",
        "training_features = feature_engineering(training_df)\n",
        "training_label = train.label.values\n",
        "\n",
        "# 4. Model training and prediction\n",
        "def modelTraining():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(12, input_dim=10, activation=\"relu\"))\n",
        "  model.add(Dense(8, activation='relu'))\n",
        "  model.add(Dense(1, activation='sigmoid')) #normalize output\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "def fitModel(training_features, training_label, candset_features, model):\n",
        "  model.fit(training_features, training_label, epochs=150, batch_size=10)\n",
        "  y_pred = model.predict_classes(candset_features)\n",
        "  return y_pred\n",
        "\n",
        "#from sklearn.model_selection import train_test_split\n",
        "#x_train,x_test, y_train, y_test = train_test_split(training_features, training_label, test_size = 0.2, random_state = 3)\n",
        "\n",
        "model = modelTraining()\n",
        "y_pred = fitModel(training_features,training_label, candset_features, model)\n",
        "#y_pred = naiveTraining(training_features,training_label, candset_features)\n",
        "#y_pred = naiveTraining(x_train,y_train, x_test, y_test)\n",
        "\n",
        "\n",
        "# 5. output\n",
        "matching_pairs = candset_df.loc[y_pred == 1, [\"id_l\", \"id_r\"]]\n",
        "matching_pairs = list(map(tuple, matching_pairs.values))\n",
        "matching_pairs_in_training = training_df.loc[training_label == 1, [\"id_l\", \"id_r\"]]\n",
        "matching_pairs_in_training = set(list(map(tuple, matching_pairs_in_training.values)))\n",
        "pred_pairs = [pair for pair in matching_pairs if\n",
        "              pair not in matching_pairs_in_training]  # remove the matching pairs already in training\n",
        "pred_pairs = np.array(pred_pairs)\n",
        "pred_df = pd.DataFrame(pred_pairs, columns=[\"ltable_id\", \"rtable_id\"])\n",
        "pred_df.to_csv(\"output.csv\", index=False)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n",
            "/content/gdrive/MyDrive/Colab Notebooks/Final Project\n",
            "Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.7/dist-packages (0.12.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (0.22.2.post1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from python-Levenshtein) (56.0.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "number of pairs originally 56376996\n",
            "number of pairs after blocking 256606\n",
            "Epoch 1/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.6339 - accuracy: 0.7141\n",
            "Epoch 2/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.2693 - accuracy: 0.9046\n",
            "Epoch 3/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.2371 - accuracy: 0.9256\n",
            "Epoch 4/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.2209 - accuracy: 0.9397\n",
            "Epoch 5/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.2157 - accuracy: 0.9429\n",
            "Epoch 6/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.2013 - accuracy: 0.9461\n",
            "Epoch 7/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.2172 - accuracy: 0.9402\n",
            "Epoch 8/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1913 - accuracy: 0.9459\n",
            "Epoch 9/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1951 - accuracy: 0.9448\n",
            "Epoch 10/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.2103 - accuracy: 0.9386\n",
            "Epoch 11/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1966 - accuracy: 0.9461\n",
            "Epoch 12/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1897 - accuracy: 0.9464\n",
            "Epoch 13/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1820 - accuracy: 0.9500\n",
            "Epoch 14/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1980 - accuracy: 0.9450\n",
            "Epoch 15/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1853 - accuracy: 0.9488\n",
            "Epoch 16/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1844 - accuracy: 0.9467\n",
            "Epoch 17/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1924 - accuracy: 0.9458\n",
            "Epoch 18/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1895 - accuracy: 0.9439\n",
            "Epoch 19/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1806 - accuracy: 0.9478\n",
            "Epoch 20/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1880 - accuracy: 0.9476\n",
            "Epoch 21/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1801 - accuracy: 0.9470\n",
            "Epoch 22/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1949 - accuracy: 0.9443\n",
            "Epoch 23/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1747 - accuracy: 0.9500\n",
            "Epoch 24/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1841 - accuracy: 0.9479\n",
            "Epoch 25/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1916 - accuracy: 0.9442\n",
            "Epoch 26/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1791 - accuracy: 0.9493\n",
            "Epoch 27/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1822 - accuracy: 0.9451\n",
            "Epoch 28/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1718 - accuracy: 0.9490\n",
            "Epoch 29/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1822 - accuracy: 0.9467\n",
            "Epoch 30/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1740 - accuracy: 0.9522\n",
            "Epoch 31/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1890 - accuracy: 0.9460\n",
            "Epoch 32/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1906 - accuracy: 0.9468\n",
            "Epoch 33/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1827 - accuracy: 0.9484\n",
            "Epoch 34/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1761 - accuracy: 0.9494\n",
            "Epoch 35/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1675 - accuracy: 0.9524\n",
            "Epoch 36/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1915 - accuracy: 0.9437\n",
            "Epoch 37/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1855 - accuracy: 0.9462\n",
            "Epoch 38/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1738 - accuracy: 0.9507\n",
            "Epoch 39/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1755 - accuracy: 0.9499\n",
            "Epoch 40/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1811 - accuracy: 0.9456\n",
            "Epoch 41/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1821 - accuracy: 0.9456\n",
            "Epoch 42/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1712 - accuracy: 0.9538\n",
            "Epoch 43/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1670 - accuracy: 0.9529\n",
            "Epoch 44/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1881 - accuracy: 0.9429\n",
            "Epoch 45/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1918 - accuracy: 0.9435\n",
            "Epoch 46/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1948 - accuracy: 0.9446\n",
            "Epoch 47/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1743 - accuracy: 0.9504\n",
            "Epoch 48/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1747 - accuracy: 0.9503\n",
            "Epoch 49/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1780 - accuracy: 0.9479\n",
            "Epoch 50/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1698 - accuracy: 0.9505\n",
            "Epoch 51/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1919 - accuracy: 0.9452\n",
            "Epoch 52/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1649 - accuracy: 0.9551\n",
            "Epoch 53/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1794 - accuracy: 0.9503\n",
            "Epoch 54/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1716 - accuracy: 0.9520\n",
            "Epoch 55/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1852 - accuracy: 0.9439\n",
            "Epoch 56/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1766 - accuracy: 0.9481\n",
            "Epoch 57/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1884 - accuracy: 0.9433\n",
            "Epoch 58/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1644 - accuracy: 0.9539\n",
            "Epoch 59/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1771 - accuracy: 0.9489\n",
            "Epoch 60/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1875 - accuracy: 0.9451\n",
            "Epoch 61/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1684 - accuracy: 0.9522\n",
            "Epoch 62/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1658 - accuracy: 0.9526\n",
            "Epoch 63/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1814 - accuracy: 0.9438\n",
            "Epoch 64/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1790 - accuracy: 0.9480\n",
            "Epoch 65/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1611 - accuracy: 0.9531\n",
            "Epoch 66/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1671 - accuracy: 0.9503\n",
            "Epoch 67/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1820 - accuracy: 0.9470\n",
            "Epoch 68/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1706 - accuracy: 0.9528\n",
            "Epoch 69/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1680 - accuracy: 0.9518\n",
            "Epoch 70/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1795 - accuracy: 0.9459\n",
            "Epoch 71/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1721 - accuracy: 0.9499\n",
            "Epoch 72/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1799 - accuracy: 0.9480\n",
            "Epoch 73/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1707 - accuracy: 0.9493\n",
            "Epoch 74/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1757 - accuracy: 0.9496\n",
            "Epoch 75/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1625 - accuracy: 0.9539\n",
            "Epoch 76/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1731 - accuracy: 0.9485\n",
            "Epoch 77/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1776 - accuracy: 0.9478\n",
            "Epoch 78/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1653 - accuracy: 0.9525\n",
            "Epoch 79/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1752 - accuracy: 0.9501\n",
            "Epoch 80/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1744 - accuracy: 0.9473\n",
            "Epoch 81/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1637 - accuracy: 0.9541\n",
            "Epoch 82/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1669 - accuracy: 0.9533\n",
            "Epoch 83/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1680 - accuracy: 0.9510\n",
            "Epoch 84/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1699 - accuracy: 0.9497\n",
            "Epoch 85/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1922 - accuracy: 0.9410\n",
            "Epoch 86/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1655 - accuracy: 0.9528\n",
            "Epoch 87/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1701 - accuracy: 0.9519\n",
            "Epoch 88/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1663 - accuracy: 0.9534\n",
            "Epoch 89/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1673 - accuracy: 0.9515\n",
            "Epoch 90/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1695 - accuracy: 0.9502\n",
            "Epoch 91/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1868 - accuracy: 0.9453\n",
            "Epoch 92/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1718 - accuracy: 0.9493\n",
            "Epoch 93/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1666 - accuracy: 0.9515\n",
            "Epoch 94/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1736 - accuracy: 0.9477\n",
            "Epoch 95/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1791 - accuracy: 0.9448\n",
            "Epoch 96/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1691 - accuracy: 0.9500\n",
            "Epoch 97/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1779 - accuracy: 0.9448\n",
            "Epoch 98/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1536 - accuracy: 0.9570\n",
            "Epoch 99/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1617 - accuracy: 0.9527\n",
            "Epoch 100/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1624 - accuracy: 0.9524\n",
            "Epoch 101/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1591 - accuracy: 0.9522\n",
            "Epoch 102/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1778 - accuracy: 0.9443\n",
            "Epoch 103/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1748 - accuracy: 0.9455\n",
            "Epoch 104/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1725 - accuracy: 0.9521\n",
            "Epoch 105/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1676 - accuracy: 0.9503\n",
            "Epoch 106/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1722 - accuracy: 0.9486\n",
            "Epoch 107/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1685 - accuracy: 0.9489\n",
            "Epoch 108/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1768 - accuracy: 0.9479\n",
            "Epoch 109/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1654 - accuracy: 0.9518\n",
            "Epoch 110/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1649 - accuracy: 0.9520\n",
            "Epoch 111/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1809 - accuracy: 0.9444\n",
            "Epoch 112/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1728 - accuracy: 0.9496\n",
            "Epoch 113/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1651 - accuracy: 0.9498\n",
            "Epoch 114/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1606 - accuracy: 0.9524\n",
            "Epoch 115/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1751 - accuracy: 0.9485\n",
            "Epoch 116/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1601 - accuracy: 0.9537\n",
            "Epoch 117/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1684 - accuracy: 0.9487\n",
            "Epoch 118/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1717 - accuracy: 0.9521\n",
            "Epoch 119/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1746 - accuracy: 0.9498\n",
            "Epoch 120/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1676 - accuracy: 0.9510\n",
            "Epoch 121/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1702 - accuracy: 0.9505\n",
            "Epoch 122/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1698 - accuracy: 0.9476\n",
            "Epoch 123/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1723 - accuracy: 0.9500\n",
            "Epoch 124/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1725 - accuracy: 0.9471\n",
            "Epoch 125/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1520 - accuracy: 0.9552\n",
            "Epoch 126/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1755 - accuracy: 0.9464\n",
            "Epoch 127/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1557 - accuracy: 0.9550\n",
            "Epoch 128/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1714 - accuracy: 0.9494\n",
            "Epoch 129/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1741 - accuracy: 0.9475\n",
            "Epoch 130/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1740 - accuracy: 0.9495\n",
            "Epoch 131/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1710 - accuracy: 0.9478\n",
            "Epoch 132/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1679 - accuracy: 0.9504\n",
            "Epoch 133/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1760 - accuracy: 0.9467\n",
            "Epoch 134/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1627 - accuracy: 0.9512\n",
            "Epoch 135/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1664 - accuracy: 0.9490\n",
            "Epoch 136/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1622 - accuracy: 0.9509\n",
            "Epoch 137/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1763 - accuracy: 0.9500\n",
            "Epoch 138/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1738 - accuracy: 0.9469\n",
            "Epoch 139/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1532 - accuracy: 0.9550\n",
            "Epoch 140/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1682 - accuracy: 0.9488\n",
            "Epoch 141/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1620 - accuracy: 0.9543\n",
            "Epoch 142/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1618 - accuracy: 0.9547\n",
            "Epoch 143/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1619 - accuracy: 0.9530\n",
            "Epoch 144/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1502 - accuracy: 0.9564\n",
            "Epoch 145/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1656 - accuracy: 0.9509\n",
            "Epoch 146/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1626 - accuracy: 0.9502\n",
            "Epoch 147/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1580 - accuracy: 0.9504\n",
            "Epoch 148/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1624 - accuracy: 0.9525\n",
            "Epoch 149/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1732 - accuracy: 0.9499\n",
            "Epoch 150/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1635 - accuracy: 0.9536\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mruqnD7pRwOP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}