{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "solution.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNRDEhkoYvd7D+mg3WyR5cl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Srishtimend/CS4400-Final/blob/main/solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSIt-C2TKXK6",
        "outputId": "0aa9fa29-64f2-4729-d3a7-fa8b02abd3e0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "%cd /content/gdrive/MyDrive/Colab\\ Notebooks/Final Project\n",
        "!pip install python-Levenshtein scikit-learn pandas numpy\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# from os.path import join\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from os.path import join\n",
        "\n",
        "# 1. read data\n",
        "\n",
        "ltable = pd.read_csv(join('data', \"ltable.csv\"))\n",
        "rtable = pd.read_csv(join('data', \"rtable.csv\"))\n",
        "train = pd.read_csv(join('data', \"train.csv\"))\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "# 2. blocking\n",
        "def pairs2LR(ltable, rtable, candset):\n",
        "    ltable.index = ltable.id\n",
        "    rtable.index = rtable.id\n",
        "    pairs = np.array(candset)\n",
        "    tpls_l = ltable.loc[pairs[:, 0], :]\n",
        "    tpls_r = rtable.loc[pairs[:, 1], :]\n",
        "    tpls_l.columns = [col + \"_l\" for col in tpls_l.columns]\n",
        "    tpls_r.columns = [col + \"_r\" for col in tpls_r.columns]\n",
        "    tpls_l.reset_index(inplace=True, drop=True)\n",
        "    tpls_r.reset_index(inplace=True, drop=True)\n",
        "    LR = pd.concat([tpls_l, tpls_r], axis=1)\n",
        "    return LR\n",
        "\n",
        "\n",
        "def block_by_brand(ltable, rtable):\n",
        "    # ensure brand is str\n",
        "    ltable['brand'] = ltable['brand'].astype(str)\n",
        "    rtable['brand'] = rtable['brand'].astype(str)\n",
        "\n",
        "    # get all brands\n",
        "    brands_l = set(ltable[\"brand\"].values)\n",
        "    brands_r = set(rtable[\"brand\"].values)\n",
        "    brands = brands_l.union(brands_r)\n",
        "\n",
        "    # map each brand to left ids and right ids\n",
        "    brand2ids_l = {b.lower(): [] for b in brands}\n",
        "    brand2ids_r = {b.lower(): [] for b in brands}\n",
        "    for i, x in ltable.iterrows():\n",
        "        brand2ids_l[x[\"brand\"].lower()].append(x[\"id\"])\n",
        "    for i, x in rtable.iterrows():\n",
        "        brand2ids_r[x[\"brand\"].lower()].append(x[\"id\"])\n",
        "\n",
        "    # put id pairs that share the same brand in candidate set\n",
        "    candset = []\n",
        "    for brd in brands:\n",
        "        l_ids = brand2ids_l[brd]\n",
        "        r_ids = brand2ids_r[brd]\n",
        "        for i in range(len(l_ids)):\n",
        "            for j in range(len(r_ids)):\n",
        "                candset.append([l_ids[i], r_ids[j]])\n",
        "    return candset\n",
        "\n",
        "# blocking to reduce the number of pairs to be compared\n",
        "candset = block_by_brand(ltable, rtable)\n",
        "print(\"number of pairs originally\", ltable.shape[0] * rtable.shape[0])\n",
        "print(\"number of pairs after blocking\",len(candset))\n",
        "candset_df = pairs2LR(ltable, rtable, candset)\n",
        "\n",
        "\n",
        "\n",
        "# 3. Feature engineering\n",
        "import Levenshtein as lev\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "\n",
        "\n",
        "def jaccard_similarity(row, attr):\n",
        "    x = set(row[attr + \"_l\"].lower().split())\n",
        "    y = set(row[attr + \"_r\"].lower().split())\n",
        "    return len(x.intersection(y)) / max(len(x), len(y))\n",
        "\n",
        "import nltk\n",
        "# Python3 implementation of above approach\n",
        "from math import floor, ceil\n",
        "\n",
        "# Function to calculate the\n",
        "# Jaro Similarity of two s\n",
        "def jaro_distance(s1, s2):\n",
        "\t\n",
        "\t# If the s are equal\n",
        "\tif (s1 == s2):\n",
        "\t\treturn 1.0\n",
        "\n",
        "\t# Length of two s\n",
        "\tlen1 = len(s1)\n",
        "\tlen2 = len(s2)\n",
        "\n",
        "\t# Maximum distance upto which matching\n",
        "\t# is allowed\n",
        "\tmax_dist = floor(max(len1, len2) / 2) - 1\n",
        "\n",
        "\t# Count of matches\n",
        "\tmatch = 0\n",
        "\n",
        "\t# Hash for matches\n",
        "\thash_s1 = [0] * len(s1)\n",
        "\thash_s2 = [0] * len(s2)\n",
        "\n",
        "\t# Traverse through the first\n",
        "\tfor i in range(len1):\n",
        "\n",
        "\t\t# Check if there is any matches\n",
        "\t\tfor j in range(max(0, i - max_dist),\n",
        "\t\t\t\t\tmin(len2, i + max_dist + 1)):\n",
        "\t\t\t\n",
        "\t\t\t# If there is a match\n",
        "\t\t\tif (s1[i] == s2[j] and hash_s2[j] == 0):\n",
        "\t\t\t\thash_s1[i] = 1\n",
        "\t\t\t\thash_s2[j] = 1\n",
        "\t\t\t\tmatch += 1\n",
        "\t\t\t\tbreak\n",
        "\n",
        "\t# If there is no match\n",
        "\tif (match == 0):\n",
        "\t\treturn 0.0\n",
        "\n",
        "\t# Number of transpositions\n",
        "\tt = 0\n",
        "\tpoint = 0\n",
        "\n",
        "\t# Count number of occurances\n",
        "\t# where two characters match but\n",
        "\t# there is a third matched character\n",
        "\t# in between the indices\n",
        "\tfor i in range(len1):\n",
        "\t\tif (hash_s1[i]):\n",
        "\n",
        "\t\t\t# Find the next matched character\n",
        "\t\t\t# in second\n",
        "\t\t\twhile (hash_s2[point] == 0):\n",
        "\t\t\t\tpoint += 1\n",
        "\n",
        "\t\t\tif (s1[i] != s2[point]):\n",
        "\t\t\t\tpoint += 1\n",
        "\t\t\t\tt += 1\n",
        "\tt = t//2\n",
        "\n",
        "\t# Return the Jaro Similarity\n",
        "\treturn (match/ len1 + match / len2 +\n",
        "\t\t\t(match - t + 1) / match)/ 3.0\n",
        "\n",
        "# Driver code\n",
        "s1 = \"CRATE\"\n",
        "s2 = \"TRACE\"\n",
        "\n",
        "# Prjaro Similarity of two s\n",
        "print(round(jaro_distance(s1, s2),6))\n",
        "\n",
        "# This code is contributed by mohit kumar 29\n",
        "\n",
        "def jaro_winkler(row, attr):\n",
        "   x = row[attr + \"_l\"].lower()\n",
        "   y = row[attr + \"_r\"].lower() \n",
        "   return jaro_distance(x,y)\n",
        "\n",
        "def feature_engineering(LR):\n",
        "    LR = LR.astype(str)\n",
        "    attrs = [\"title\", \"category\", \"brand\", \"modelno\", \"price\"]\n",
        "    features = []\n",
        "    for attr in attrs:\n",
        "        j_sim = LR.apply(jaccard_similarity, attr=attr, axis=1)\n",
        "        l_dist = LR.apply(jaro_winkler, attr=attr, axis=1)\n",
        "        features.append(j_sim)\n",
        "        features.append(l_dist)\n",
        "    features = np.array(features).T\n",
        "    return features\n",
        "candset_features = feature_engineering(candset_df)\n",
        "\n",
        "# also perform feature engineering to the training set\n",
        "training_pairs = list(map(tuple, train[[\"ltable_id\", \"rtable_id\"]].values))\n",
        "training_df = pairs2LR(ltable, rtable, training_pairs)\n",
        "training_features = feature_engineering(training_df)\n",
        "training_label = train.label.values\n",
        "\n",
        "# 4. Model training and prediction\n",
        "def modelTraining():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(12, input_dim=10, activation=\"relu\"))\n",
        "  model.add(Dense(8, activation='relu'))\n",
        "  model.add(Dense(1, activation='sigmoid')) #normalize output\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "def fitModel(training_features, training_label, candset_features, model):\n",
        "  #training_features, training_label, y_train, y_test = train_test_split(training_features, training_label, test_size = 0.2, shuffle = True)\n",
        "  model.fit(training_features, training_label, epochs=150, batch_size=10)\n",
        "  y_pred = model.predict_classes(candset_features)\n",
        "\n",
        "  return y_pred\n",
        "\n",
        "#from sklearn.model_selection import train_test_split\n",
        "#x_train,x_test, y_train, y_test = train_test_split(training_features, training_label, test_size = 0.2, random_state = 3)\n",
        "\n",
        "model = modelTraining()\n",
        "y_pred = fitModel(training_features,training_label, candset_features, model)\n",
        "#y_pred = naiveTraining(training_features,training_label, candset_features)\n",
        "#y_pred = naiveTraining(x_train,y_train, x_test, y_test)\n",
        "\n",
        "\n",
        "# 5. output\n",
        "matching_pairs = candset_df.loc[y_pred == 1, [\"id_l\", \"id_r\"]]\n",
        "matching_pairs = list(map(tuple, matching_pairs.values))\n",
        "matching_pairs_in_training = training_df.loc[training_label == 1, [\"id_l\", \"id_r\"]]\n",
        "matching_pairs_in_training = set(list(map(tuple, matching_pairs_in_training.values)))\n",
        "pred_pairs = [pair for pair in matching_pairs if\n",
        "              pair not in matching_pairs_in_training]  # remove the matching pairs already in training\n",
        "pred_pairs = np.array(pred_pairs)\n",
        "pred_df = pd.DataFrame(pred_pairs, columns=[\"ltable_id\", \"rtable_id\"])\n",
        "pred_df.to_csv(\"output.csv\", index=False)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n",
            "/content/gdrive/MyDrive/Colab Notebooks/Final Project\n",
            "Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.7/dist-packages (0.12.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (0.22.2.post1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from python-Levenshtein) (56.0.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "number of pairs originally 56376996\n",
            "number of pairs after blocking 256606\n",
            "0.733333\n",
            "Epoch 1/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.3666 - accuracy: 0.8993\n",
            "Epoch 2/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.2181 - accuracy: 0.9439\n",
            "Epoch 3/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.2100 - accuracy: 0.9448\n",
            "Epoch 4/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1945 - accuracy: 0.9507\n",
            "Epoch 5/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.2222 - accuracy: 0.9356\n",
            "Epoch 6/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1936 - accuracy: 0.9453\n",
            "Epoch 7/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.2052 - accuracy: 0.9420\n",
            "Epoch 8/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.2032 - accuracy: 0.9395\n",
            "Epoch 9/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1864 - accuracy: 0.9472\n",
            "Epoch 10/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.2045 - accuracy: 0.9398\n",
            "Epoch 11/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1929 - accuracy: 0.9447\n",
            "Epoch 12/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1853 - accuracy: 0.9453\n",
            "Epoch 13/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1927 - accuracy: 0.9435\n",
            "Epoch 14/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1925 - accuracy: 0.9439\n",
            "Epoch 15/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1696 - accuracy: 0.9545\n",
            "Epoch 16/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1742 - accuracy: 0.9518\n",
            "Epoch 17/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1818 - accuracy: 0.9484\n",
            "Epoch 18/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1754 - accuracy: 0.9499\n",
            "Epoch 19/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1776 - accuracy: 0.9471\n",
            "Epoch 20/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1879 - accuracy: 0.9487\n",
            "Epoch 21/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1716 - accuracy: 0.9499\n",
            "Epoch 22/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1814 - accuracy: 0.9472\n",
            "Epoch 23/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1882 - accuracy: 0.9451\n",
            "Epoch 24/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1876 - accuracy: 0.9442\n",
            "Epoch 25/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1807 - accuracy: 0.9485\n",
            "Epoch 26/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1713 - accuracy: 0.9499\n",
            "Epoch 27/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1787 - accuracy: 0.9495\n",
            "Epoch 28/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1682 - accuracy: 0.9513\n",
            "Epoch 29/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1731 - accuracy: 0.9518\n",
            "Epoch 30/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1906 - accuracy: 0.9438\n",
            "Epoch 31/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1681 - accuracy: 0.9522\n",
            "Epoch 32/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1786 - accuracy: 0.9461\n",
            "Epoch 33/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1719 - accuracy: 0.9478\n",
            "Epoch 34/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1717 - accuracy: 0.9490\n",
            "Epoch 35/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1828 - accuracy: 0.9465\n",
            "Epoch 36/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1590 - accuracy: 0.9561\n",
            "Epoch 37/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1645 - accuracy: 0.9542\n",
            "Epoch 38/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1672 - accuracy: 0.9519\n",
            "Epoch 39/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1578 - accuracy: 0.9565\n",
            "Epoch 40/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1617 - accuracy: 0.9562\n",
            "Epoch 41/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1699 - accuracy: 0.9519\n",
            "Epoch 42/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1770 - accuracy: 0.9476\n",
            "Epoch 43/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1780 - accuracy: 0.9485\n",
            "Epoch 44/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1726 - accuracy: 0.9506\n",
            "Epoch 45/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1557 - accuracy: 0.9569\n",
            "Epoch 46/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1710 - accuracy: 0.9535\n",
            "Epoch 47/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1751 - accuracy: 0.9496\n",
            "Epoch 48/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1675 - accuracy: 0.9523\n",
            "Epoch 49/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1735 - accuracy: 0.9489\n",
            "Epoch 50/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1819 - accuracy: 0.9467\n",
            "Epoch 51/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1519 - accuracy: 0.9576\n",
            "Epoch 52/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1840 - accuracy: 0.9439\n",
            "Epoch 53/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1715 - accuracy: 0.9499\n",
            "Epoch 54/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1625 - accuracy: 0.9515\n",
            "Epoch 55/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1736 - accuracy: 0.9488\n",
            "Epoch 56/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1762 - accuracy: 0.9481\n",
            "Epoch 57/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1564 - accuracy: 0.9552\n",
            "Epoch 58/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1658 - accuracy: 0.9524\n",
            "Epoch 59/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1585 - accuracy: 0.9537\n",
            "Epoch 60/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1658 - accuracy: 0.9516\n",
            "Epoch 61/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1732 - accuracy: 0.9498\n",
            "Epoch 62/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1579 - accuracy: 0.9582\n",
            "Epoch 63/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1851 - accuracy: 0.9480\n",
            "Epoch 64/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1631 - accuracy: 0.9535\n",
            "Epoch 65/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1901 - accuracy: 0.9424\n",
            "Epoch 66/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1778 - accuracy: 0.9487\n",
            "Epoch 67/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1673 - accuracy: 0.9533\n",
            "Epoch 68/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1761 - accuracy: 0.9494\n",
            "Epoch 69/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1632 - accuracy: 0.9499\n",
            "Epoch 70/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1688 - accuracy: 0.9535\n",
            "Epoch 71/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1758 - accuracy: 0.9480\n",
            "Epoch 72/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1772 - accuracy: 0.9479\n",
            "Epoch 73/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1776 - accuracy: 0.9493\n",
            "Epoch 74/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1756 - accuracy: 0.9470\n",
            "Epoch 75/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1646 - accuracy: 0.9537\n",
            "Epoch 76/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1681 - accuracy: 0.9519\n",
            "Epoch 77/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1580 - accuracy: 0.9556\n",
            "Epoch 78/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1573 - accuracy: 0.9550\n",
            "Epoch 79/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1986 - accuracy: 0.9412\n",
            "Epoch 80/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1764 - accuracy: 0.9500\n",
            "Epoch 81/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1556 - accuracy: 0.9555\n",
            "Epoch 82/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1705 - accuracy: 0.9502\n",
            "Epoch 83/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1824 - accuracy: 0.9435\n",
            "Epoch 84/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1591 - accuracy: 0.9545\n",
            "Epoch 85/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1524 - accuracy: 0.9568\n",
            "Epoch 86/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1574 - accuracy: 0.9555\n",
            "Epoch 87/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1617 - accuracy: 0.9524\n",
            "Epoch 88/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1592 - accuracy: 0.9534\n",
            "Epoch 89/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1726 - accuracy: 0.9470\n",
            "Epoch 90/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1649 - accuracy: 0.9503\n",
            "Epoch 91/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1722 - accuracy: 0.9503\n",
            "Epoch 92/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1759 - accuracy: 0.9476\n",
            "Epoch 93/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1525 - accuracy: 0.9521\n",
            "Epoch 94/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1569 - accuracy: 0.9551\n",
            "Epoch 95/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1634 - accuracy: 0.9525\n",
            "Epoch 96/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1490 - accuracy: 0.9585\n",
            "Epoch 97/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1800 - accuracy: 0.9449\n",
            "Epoch 98/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1615 - accuracy: 0.9537\n",
            "Epoch 99/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1627 - accuracy: 0.9527\n",
            "Epoch 100/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1693 - accuracy: 0.9487\n",
            "Epoch 101/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1752 - accuracy: 0.9493\n",
            "Epoch 102/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1689 - accuracy: 0.9513\n",
            "Epoch 103/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1486 - accuracy: 0.9572\n",
            "Epoch 104/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1524 - accuracy: 0.9536\n",
            "Epoch 105/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1600 - accuracy: 0.9548\n",
            "Epoch 106/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1570 - accuracy: 0.9506\n",
            "Epoch 107/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1714 - accuracy: 0.9506\n",
            "Epoch 108/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1620 - accuracy: 0.9539\n",
            "Epoch 109/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1594 - accuracy: 0.9544\n",
            "Epoch 110/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1537 - accuracy: 0.9542\n",
            "Epoch 111/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1646 - accuracy: 0.9540\n",
            "Epoch 112/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1557 - accuracy: 0.9537\n",
            "Epoch 113/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1582 - accuracy: 0.9515\n",
            "Epoch 114/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1706 - accuracy: 0.9490\n",
            "Epoch 115/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1648 - accuracy: 0.9518\n",
            "Epoch 116/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1690 - accuracy: 0.9484\n",
            "Epoch 117/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1696 - accuracy: 0.9510\n",
            "Epoch 118/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1639 - accuracy: 0.9537\n",
            "Epoch 119/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1543 - accuracy: 0.9546\n",
            "Epoch 120/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1526 - accuracy: 0.9562\n",
            "Epoch 121/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1604 - accuracy: 0.9510\n",
            "Epoch 122/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1648 - accuracy: 0.9504\n",
            "Epoch 123/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1582 - accuracy: 0.9518\n",
            "Epoch 124/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1743 - accuracy: 0.9494\n",
            "Epoch 125/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1579 - accuracy: 0.9559\n",
            "Epoch 126/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1698 - accuracy: 0.9466\n",
            "Epoch 127/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1580 - accuracy: 0.9532\n",
            "Epoch 128/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1586 - accuracy: 0.9535\n",
            "Epoch 129/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1538 - accuracy: 0.9528\n",
            "Epoch 130/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1675 - accuracy: 0.9485\n",
            "Epoch 131/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1707 - accuracy: 0.9504\n",
            "Epoch 132/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1662 - accuracy: 0.9510\n",
            "Epoch 133/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1625 - accuracy: 0.9518\n",
            "Epoch 134/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1738 - accuracy: 0.9480\n",
            "Epoch 135/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1526 - accuracy: 0.9552\n",
            "Epoch 136/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1650 - accuracy: 0.9496\n",
            "Epoch 137/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1655 - accuracy: 0.9501\n",
            "Epoch 138/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1581 - accuracy: 0.9525\n",
            "Epoch 139/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1596 - accuracy: 0.9513\n",
            "Epoch 140/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1629 - accuracy: 0.9503\n",
            "Epoch 141/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1542 - accuracy: 0.9550\n",
            "Epoch 142/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1566 - accuracy: 0.9550\n",
            "Epoch 143/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1588 - accuracy: 0.9524\n",
            "Epoch 144/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1483 - accuracy: 0.9544\n",
            "Epoch 145/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1566 - accuracy: 0.9520\n",
            "Epoch 146/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1518 - accuracy: 0.9554\n",
            "Epoch 147/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1639 - accuracy: 0.9506\n",
            "Epoch 148/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1599 - accuracy: 0.9512\n",
            "Epoch 149/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1589 - accuracy: 0.9546\n",
            "Epoch 150/150\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 0.1524 - accuracy: 0.9543\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Dg23d7RKyoJ",
        "outputId": "4dcdcba1-a951-4369-dd3d-b80eccd37488"
      },
      "source": [
        "y_pred"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.03912979],\n",
              "       [0.03499398],\n",
              "       [0.03887129],\n",
              "       ...,\n",
              "       [0.02819926],\n",
              "       [0.0592491 ],\n",
              "       [0.01696089]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mruqnD7pRwOP"
      },
      "source": [
        "#num_matches = 3000\n",
        "#res = sorted(range(len(y_pred)), key = lambda sub: y_pred[sub], reverse=False)[-num_matches:]\n"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_CMFxgMMR0A"
      },
      "source": [
        ""
      ],
      "execution_count": 54,
      "outputs": []
    }
  ]
}